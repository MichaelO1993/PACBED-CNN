{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lyric-weather",
   "metadata": {},
   "source": [
    "# CNN-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitted-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aging-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters - CNN-Training\n",
    "parameters_training = {\n",
    "    'reg_id' : 1,  # Number of the register entry\n",
    "    'conv_range' : None,             # [mrad] Convergence angle range, for which models should be trained, None -> no filtering\n",
    "    'thickness_range' : None        # [nm]   Thickness range, for which models should be trained, None -> no filtering\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hollywood-atlantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OBERAI~1\\AppData\\Local\\Temp/ipykernel_10600/2797239043.py:8: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code Snippet limits GPU memory growth -> without, errors occur (may not necessary for cluster/other computers)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=\n",
    "                                  tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "                                  # device_count = {'GPU': 1}\n",
    "                                  )\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atmospheric-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_PACBED_Trainer:\n",
    "    def __init__(self, parameters):\n",
    "        # Declare variables\n",
    "        self.Reg_id = parameters['reg_id']\n",
    "\n",
    "        self.df = None\n",
    "        self.df_filtered = None\n",
    "        self.df_train = None\n",
    "        self.df_validation = None\n",
    "        self.dim = None\n",
    "        self.rescaling = None\n",
    "        \n",
    "        # Get register entry\n",
    "        path = self.make_register()\n",
    "        \n",
    "        # Load dataframe\n",
    "        self.df = pd.read_csv(os.path.join(path, 'simulation', 'df.csv'), sep = ';')\n",
    "        \n",
    "    def make_register(self,):\n",
    "        # Load register file\n",
    "        df_register = pd.read_csv('.\\\\data\\\\Register.csv', sep = ';', index_col = 'id')\n",
    "        \n",
    "        # Get parameters\n",
    "        df_system = df_register.loc[self.Reg_id]\n",
    "        print(f'Loaded system: \\n')\n",
    "        display(df_system)\n",
    "       \n",
    "        self.path_models = os.path.join(df_system.loc[self.Reg_id]['path'], 'models')\n",
    "        # Check if already trained model is present\n",
    "        if not os.path.exists(self.path_models):\n",
    "            # Make path for saving models\n",
    "            os.mkdir(self.path_models)\n",
    "            \n",
    "            # Make register for the models\n",
    "            column_names = ['id', 'path', 'thickness', 'convergenc angle min', 'convergenc angle max']\n",
    "            self.df_register_model = pd.DataFrame(columns = column_names)\n",
    "            self.df_register_model.set_index('id')\n",
    "\n",
    "            self.reg_id_model = 0\n",
    "            \n",
    "        else:\n",
    "            self.df_register_model = pd.read_csv(os.path.join(self.path_models, 'Register_models.csv'), sep = ';', index_col = 'id')\n",
    "            \n",
    "            self.reg_id_model = np.amax(self.df_register_model.index) + 1\n",
    "            \n",
    "        self.path_model = os.path.join(self.path_models, str(self.reg_id_model))\n",
    "        \n",
    "        os.mkdir(self.path_model)    \n",
    "            \n",
    "        # Save entry\n",
    "        data_entry = [self.path_model, df_system.loc[self.Reg_id]['thickness'], df_system.loc[self.Reg_id]['convergenc angle min'], df_system.loc[self.Reg_id]['convergenc angle max']]\n",
    "        df_model = pd.DataFrame(data = [data_entry], columns = self.df_register_model.columns, index = [self.reg_id_model])\n",
    "        self.df_register_model = pd.concat([self.df_register_model, df_model], ignore_index = False)\n",
    "        self.df_register_model.to_csv(os.path.join(self.path_models, 'Register_models.csv'), sep = ';', index = True, index_label = 'id')\n",
    "        \n",
    "        return df_system.loc[self.Reg_id]['path']\n",
    "            \n",
    "    \n",
    "    # Filter trainings dataset to conv_range and thickness_range\n",
    "    def filter_dataset(self, conv_range = None, thickness_range = None):\n",
    "        if conv_range == None:\n",
    "            self.df_filtered = self.df\n",
    "            print('Model will be trained from ({:.1f} to {:.1f}) mrad convergence angle.'.format(np.amin(self.df['Conv_Angle']), np.amax(self.df['Conv_Angle'])))\n",
    "        else:\n",
    "            self.df_filtered = self.df[(self.df['Conv_Angle'] >= np.amin(conv_range)) & (self.df['Conv_Angle'] <= np.amax(conv_range))]\n",
    "            print('Model will be trained from ({:.1f} to {:.1f}) mrad convergence angle.'.format(np.amin(self.df_filtered['Conv_Angle']), np.amax(self.df_filtered['Conv_Angle'])))\n",
    "        \n",
    "        if thickness_range == None:\n",
    "            print('Model will be trained from ({:.1f} to {:.1f}) nm thickness.'.format(np.amin(self.df['Thickness'])/10, np.amax(self.df['Thickness']/10)))\n",
    "        else:\n",
    "            self.df_filtered = self.df[(self.df_filtered['Thickness'] >= np.amin(thickness_range)) & (self.df_filtered['Thickness'] <= np.amax(thickness_range))]\n",
    "            print('Model will be trained from ({:.1f} to {:.1f}) nm thickness.'.format(np.amin(self.df_filtered['Thickness'])/10, np.amax(self.df_filtered['Thickness']/10)))\n",
    "\n",
    "        self.df_filtered.reset_index()\n",
    "        \n",
    "        # Preparing Dataframe for training and validation\n",
    "        splitting_ratio = 0.1\n",
    "        self.df_train, self.df_validation = train_test_split(self.df_filtered, test_size=splitting_ratio)\n",
    "        \n",
    "        print('Number of images: {}'.format(len(self.df_filtered)))\n",
    "        print('{:.0f}% used for training, {:.0f}% used for validation'.format((1-splitting_ratio)*100, splitting_ratio*100))\n",
    "        \n",
    "        # Update model register file\n",
    "        self.df_register_model.loc[self.df_register_model['id'] == self.reg_id_model, 'convergenc angle min'] = np.amin(self.df_filtered['Conv_Angle'])\n",
    "        self.df_register_model.loc[self.df_register_model['id'] == self.reg_id_model, 'convergenc angle max'] = np.amax(self.df_filtered['Conv_Angle'])\n",
    "        self.df_register_model.loc[self.df_register_model['id'] == self.reg_id_model, 'thickness'] = np.amax(self.df_filtered['Thickness'])/10\n",
    "\n",
    "        self.df_register_model.to_csv(os.path.join(self.path_models, 'Register_models.csv'), sep = ';', index=False)\n",
    "        \n",
    "        \n",
    "    # Define dimension of CNN input\n",
    "    def CNN_dim(self, dim = (0,0,0)):\n",
    "        # If no dim input given, an example image will be loaded and used for dimension determination --> no rescaling required\n",
    "        if dim == (0,0,0):\n",
    "            self.dim = np.array(Image.open(self.df['Path'][0])).shape\n",
    "            self.rescaling = False\n",
    "        else:\n",
    "            self.dim = dim\n",
    "            self.rescaling = True\n",
    "            \n",
    "        # Convert dimension to rgb (required for pretrained models), otherwise grayscale can be used also\n",
    "        if len(self.dim) == 3:\n",
    "            self.dim = list(self.dim)\n",
    "            self.dim[-1] = 3\n",
    "        else:\n",
    "            self.dim = self.dim + (3,)\n",
    "        print('Shape of CNN input: {}'.format(self.dim))\n",
    "    \n",
    "    def build_model(self, n_classes, fc_layers = [1024, 1024], dropout = 0.3):\n",
    "        \n",
    "        # Load pretrainerd xception model (can be changed with other models or non-pretrained model)\n",
    "        base_model = tf.keras.applications.Xception(weights = 'imagenet',\n",
    "                                                    include_top = False,\n",
    "                                                    pooling = 'avg', # max pooling may perform better or worse\n",
    "                                                    input_shape = self.dim)\n",
    "        # Build model\n",
    "        \n",
    "        # Inputs\n",
    "        inputs_img = tf.keras.Input(shape=self.dim) # Image\n",
    "        input_conv = tf.keras.Input(shape=(1))      # Cnvergence angle\n",
    "\n",
    "        # Pretrained model\n",
    "        x = base_model(inputs_img)\n",
    "\n",
    "        # Build up fully connected layers with dropout\n",
    "        for fc in fc_layers:\n",
    "            x = tf.keras.layers.Dense(fc, activation='relu')(x)\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        # Add second input, convergence angel\n",
    "        x = tf.keras.layers.Concatenate(axis=1)([x, input_conv])\n",
    "\n",
    "        # Number of putputs defined by the datagenerator\n",
    "        outputs = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "        \n",
    "        # Full model\n",
    "        model = tf.keras.Model(inputs = (inputs_img, input_conv), outputs = outputs)        \n",
    "        print(model.summary())\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def CNN_training(self, model, datagenerator_train, datagenerator_validation, epochs, path):\n",
    "    \n",
    "        # Callback functions for saving the model with the lowest validation loss --> used for final model\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=path,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "\n",
    "        # Compile  model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(),\n",
    "                      metrics=[tf.keras.metrics.CategoricalAccuracy()]) \n",
    "\n",
    "        # Train model\n",
    "        history_train = model.fit(datagenerator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  validation_data=datagenerator_validation,\n",
    "                                  callbacks=[model_checkpoint_callback]\n",
    "                                  )\n",
    "\n",
    "        return history_train\n",
    "    \n",
    "    \n",
    "    def train_thickness(self, epochs = 80, batch_size = 8):\n",
    "        # Generate labels\n",
    "        label_thickness, scale_vec = self.label_gen('Thickness', self.df_filtered)\n",
    "        \n",
    "        # Initialize datagenerator\n",
    "        datagenerator_thickness_train = self.DataGenerator(self.df_train, label_thickness, 'Thickness', self.rescaling, self.dim, batch_size, shuffle=True, scale_vec=scale_vec)\n",
    "        datagenerator_thickness_validation = self.DataGenerator(self.df_validation, label_thickness, 'Thickness', self.rescaling, self.dim, batch_size, shuffle=False, scale_vec=scale_vec)\n",
    "\n",
    "        # Generate model\n",
    "        model_thickness = self.build_model(n_classes = len(label_thickness))\n",
    "        \n",
    "        # Train model\n",
    "        checkpoint_filepath = os.path.join(self.path_model, 'Thickness')\n",
    "        history_thickness_train = self.CNN_training(model_thickness, datagenerator_thickness_train, datagenerator_thickness_validation, epochs, checkpoint_filepath)\n",
    "        \n",
    "        # Transform tensorflow SavedModel to tensorflow lite models\n",
    "        self.transform_model(checkpoint_filepath)\n",
    "        \n",
    "        print('Training finished!')\n",
    "        \n",
    "    def train_mistilt(self, epochs = 40, batch_size = 8):\n",
    "        # Generate labels\n",
    "        label_mistilt, scale_vec = self.label_gen('Mistilt', self.df_filtered)\n",
    "        \n",
    "        # Initialize datagenerator\n",
    "        datagenerator_mistilt_train = self.DataGenerator(self.df_train, label_mistilt, 'Mistilt', self.rescaling, self.dim, batch_size, shuffle=True, scale_vec=scale_vec)\n",
    "        datagenerator_mistilt_validation = self.DataGenerator(self.df_validation, label_mistilt, 'Mistilt', self.rescaling, self.dim, batch_size, shuffle=False, scale_vec=scale_vec)\n",
    "\n",
    "        # Generate model\n",
    "        model_mistilt = self.build_model(n_classes = len(label_mistilt))\n",
    "        \n",
    "        # Train model\n",
    "        checkpoint_filepath = os.path.join(self.path_model, 'Mistilt')\n",
    "        history_mistilt_train = self.CNN_training(model_mistilt, datagenerator_mistilt_train, datagenerator_mistilt_validation, epochs, checkpoint_filepath)\n",
    "        \n",
    "        # Transform tensorflow SavedModel to tensorflow lite models\n",
    "        self.transform_model(checkpoint_filepath)      \n",
    "        \n",
    "        print('Training finished!')\n",
    "        \n",
    "    def train_scale(self, epochs = 20, batch_size = 8):\n",
    "        # Generate labels\n",
    "        label_scale, scale_vec = self.label_gen('Scale', self.df_filtered)\n",
    "        \n",
    "        # Initialize datagenerator\n",
    "        datagenerator_scale_train = self.DataGenerator(self.df_train, label_scale, 'Scale', self.rescaling, self.dim, batch_size, shuffle=True, scale_vec=scale_vec)\n",
    "        datagenerator_scale_validation = self.DataGenerator(self.df_validation, label_scale, 'Scale', self.rescaling, self.dim, batch_size, shuffle=False, scale_vec=scale_vec)\n",
    "\n",
    "        # Generate model\n",
    "        model_scale = self.build_model(n_classes = len(label_scale))\n",
    "        \n",
    "        # Train model\n",
    "        checkpoint_filepath = os.path.join(self.path_model, 'Scale')\n",
    "        history_scale_train = self.CNN_training(model_scale, datagenerator_scale_train, datagenerator_scale_validation, epochs, checkpoint_filepath)\n",
    "        \n",
    "        # Transform tensorflow SavedModel to tensorflow lite models\n",
    "        self.transform_model(checkpoint_filepath)\n",
    "        \n",
    "        print('Training finished!')\n",
    "        \n",
    "    def transform_model(self, path):\n",
    "        # Convert to tensorflow lite framework\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(path)\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        # Save the model.\n",
    "        with open(os.path.join(path + '.tflite'), 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        # Delete tensorflow saved model\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "    def label_gen(self, case, dataframe):\n",
    "        # Generate labels\n",
    "        if case == 'Thickness':\n",
    "            # Number of different classes\n",
    "            label_unique = np.unique(dataframe['Thickness'])\n",
    "            # Save as dataframe\n",
    "            df_labels = pd.DataFrame({'Thickness / A' : label_unique,'Index' : np.arange(0,len(label_unique))})\n",
    "            # Only required for scaling\n",
    "            scale_vec = None\n",
    "        elif case == 'Mistilt':\n",
    "            # Number of different classes\n",
    "            label_unique = np.unique(dataframe['Mistilt'])\n",
    "            # Save as dataframe\n",
    "            df_labels = pd.DataFrame({'Mistilt / mrad' : label_unique,'Index' : np.arange(0,len(label_unique))})\n",
    "            # Only required for scaling\n",
    "            scale_vec = None\n",
    "        elif case == 'Scale':\n",
    "            # Used scaling operations\n",
    "            scale_vec = [0.6, 0.8, 1, 1.2, 1.4, 1.6, 1.8]\n",
    "            # Number of different classes\n",
    "            label_unique = np.unique(scale_vec)\n",
    "            # Save as dataframe\n",
    "            df_labels = pd.DataFrame({'Scale / []' : label_unique,'Index' : np.arange(0,len(label_unique))})\n",
    "            \n",
    "        # Save labels\n",
    "        df_labels.to_csv(os.path.join(self.path_model, case + '_labels.csv'), sep = ';', index=False)\n",
    "        print('Number of labels: {}'.format(len(df_labels)))\n",
    "        \n",
    "        return df_labels, scale_vec\n",
    "\n",
    "    # Make custom data generator\n",
    "    class DataGenerator(tf.keras.utils.Sequence):\n",
    "        def __init__(self, df, labels, case, rescaling, dim=(299, 299, 1), batch_size=8, shuffle=True, scale_vec=None):\n",
    "            # Declare variables\n",
    "            self.batch_size = batch_size\n",
    "            self.df = df.copy(deep=True)\n",
    "            self.indices = self.df.index.tolist()\n",
    "            self.labels = labels\n",
    "            self.num_classes = len(self.labels)\n",
    "            self.shuffle = shuffle\n",
    "            self.case = case\n",
    "            self.dim = dim\n",
    "            self.on_epoch_end()\n",
    "            self.scale_vec = scale_vec\n",
    "            self.rescaling = rescaling\n",
    "\n",
    "            # Normalize convergence angle input\n",
    "            self.conv_borders = [np.amin(self.df['Conv_Angle']), np.amax(self.df['Conv_Angle'])]\n",
    "\n",
    "            if self.conv_borders[0] - self.conv_borders[1] == 0:\n",
    "                self.df.loc[:, 'Conv_Angle_normed'] = 1\n",
    "            else:\n",
    "                self.conv_ratio = self.conv_borders[0]/(self.conv_borders[1]-self.conv_borders[0])\n",
    "                self.df['Conv_Angle_normed'] = self.df['Conv_Angle']/(self.conv_borders[1]-self.conv_borders[0]) - self.conv_ratio\n",
    "\n",
    "        def __len__(self):\n",
    "            return int(np.floor(len(self.indices) / self.batch_size))\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "            batch = [self.indices[k] for k in index]\n",
    "\n",
    "            X, y = self.__get_data(batch)\n",
    "            return X, y\n",
    "\n",
    "        def on_epoch_end(self):\n",
    "            self.index = np.arange(len(self.indices))\n",
    "            if self.shuffle == True:\n",
    "                np.random.shuffle(self.index)\n",
    "\n",
    "        def __get_label(self, label_id):\n",
    "            # One Hot Encoding (maybe integer encoding better suitable)\n",
    "            label_id = tf.keras.utils.to_categorical(label_id, self.num_classes)\n",
    "            return label_id\n",
    "\n",
    "        def __get_data(self, batch):\n",
    "            X = np.empty((self.batch_size, *self.dim))\n",
    "            X_conv = np.empty((self.batch_size, 1))\n",
    "            y = np.empty((self.batch_size, self.num_classes))\n",
    "\n",
    "            for i, id in enumerate(batch):\n",
    "\n",
    "                # Loading image\n",
    "                img = Image.open(self.df['Path'][id])\n",
    "                img_arr = np.array(img)\n",
    "\n",
    "                # If grayscale, add a dimension (required for tensorflow)\n",
    "                if len(img.size) == 2:\n",
    "                    img_arr = np.array(img)[:, :, np.newaxis].astype(np.float32)\n",
    "\n",
    "                # Normalize image and change datatype\n",
    "                img_arr = ((img_arr-np.amin(img_arr)) / (np.amax(img_arr)-np.amin(img_arr))).astype(np.float32)\n",
    "\n",
    "                # Resize image to the required dimension - Image already correct dimension --> save time by commenting out\n",
    "                if self.rescaling:\n",
    "                    img_arr = tf.keras.preprocessing.image.smart_resize(img_arr, self.dim[0:2], interpolation='bilinear')\n",
    "\n",
    "\n",
    "                # Loading Label for different cases (for scaling the label depends on the applied scale_rnd value)\n",
    "                if self.case == 'Thickness':\n",
    "                    y_val = self.df['Thickness'][id]\n",
    "                elif self.case == 'Mistilt':\n",
    "                    y_val = self.df['Mistilt'][id]\n",
    "                elif self.case == 'Scale':\n",
    "                    # Make a random scaling operation from the given vector\n",
    "                    scale_rnd = self.scale_vec[np.random.randint(len(self.scale_vec), size=1)[0]]\n",
    "                    # Scale image\n",
    "                    img_arr = tf.keras.preprocessing.image.apply_affine_transform(img_arr, zx=scale_rnd, zy=scale_rnd, row_axis=0, col_axis=1, channel_axis=2, fill_mode='constant', cval=0., order=1)\n",
    "                    y_val = scale_rnd\n",
    "\n",
    "                # Get categorical labels, one-hot encoded\n",
    "                y[i,] = self.__get_label(np.array(self.labels.loc[self.labels.iloc[:, 0] == y_val, 'Index']))\n",
    "\n",
    "\n",
    "                # Random scaling only if scale is not trained (equal zooming in x and y, no straining)\n",
    "                if self.case != 'Scale':\n",
    "                    # Zoom image\n",
    "                    zoom = np.random.uniform(0.8,1.2)\n",
    "                    # Allow small random stretching\n",
    "                    zoom_x = np.random.normal(zoom, 0.07)\n",
    "                    zoom_y = np.random.normal(zoom, 0.07)\n",
    "                    img_arr = tf.keras.preprocessing.image.apply_affine_transform(img_arr, zx=zoom_x, zy=zoom_y, row_axis=0, col_axis=1, channel_axis=2, fill_mode='constant', cval=0., order=1)\n",
    "\n",
    "\n",
    "                # Random shear\n",
    "                img_arr = tf.keras.preprocessing.image.random_shear(img_arr, intensity=0.05, row_axis=0, col_axis=1,\n",
    "                                                                    channel_axis=2, fill_mode='constant', cval=0.0,\n",
    "                                                                    interpolation_order=1)\n",
    "\n",
    "                # Random rotation (may change rotation from 45° to 90°)\n",
    "                img_arr = tf.keras.preprocessing.image.random_rotation(img_arr, rg=50, row_axis=0, col_axis=1,\n",
    "                                                                       channel_axis=2, fill_mode='constant', cval=0.0,\n",
    "                                                                       interpolation_order=1)\n",
    "\n",
    "                 # Random vertical and horizontal shift\n",
    "                img_arr = tf.keras.preprocessing.image.random_shift(img_arr, wrg=0.1, hrg=0.1, row_axis=0, col_axis=1,\n",
    "                                                                    channel_axis=2, fill_mode='constant', cval=0.0,\n",
    "                                                                    interpolation_order=1)           \n",
    "\n",
    "                # Random flip left/right and up/down\n",
    "                if random.choice([0, 1]):\n",
    "                    img_arr = tf.image.flip_left_right(img_arr)\n",
    "                if random.choice([0, 1]):\n",
    "                    img_arr = tf.image.flip_up_down(img_arr)\n",
    "\n",
    "\n",
    "                # Add poisson noise: The larger the value the smaller the noise becomes, Poisson noise no negative values valid --> relu function\n",
    "                noise_strength = np.random.randint(1, high=201, dtype=int)\n",
    "                img_arr = np.random.poisson(tf.nn.relu(img_arr)*noise_strength)/noise_strength\n",
    "\n",
    "                # Normalize between -1 to 1 (due to keras input for xception model)\n",
    "                img_arr = 2*(img_arr-np.amin(img_arr))/(np.amax(img_arr)-np.amin(img_arr))-1\n",
    "\n",
    "                # Get convergence angle and normalize it\n",
    "                conv_normed = self.df['Conv_Angle_normed'][id]\n",
    "                \n",
    "                # Add gaussian noise, because user will not give exactly convergence angle\n",
    "                conv_normed = np.random.normal(conv_normed, 0.05)\n",
    "\n",
    "                # Filling batch\n",
    "                X[i,] = (np.stack((img_arr[:,:,0],)*self.dim[2], axis=-1)).astype(np.float32)\n",
    "\n",
    "                #X[i,] = img_arr\n",
    "                X_conv[i,] = np.float32(conv_normed)\n",
    "\n",
    "            return (X, X_conv), y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conservative-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded system: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>material</th>\n",
       "      <th>composition</th>\n",
       "      <th>direction</th>\n",
       "      <th>thickness</th>\n",
       "      <th>thickness step</th>\n",
       "      <th>high tension</th>\n",
       "      <th>convergenc angle min</th>\n",
       "      <th>convergenc angle max</th>\n",
       "      <th>convergenc angle step</th>\n",
       "      <th>mistilt min</th>\n",
       "      <th>mistilt max</th>\n",
       "      <th>mistilt step</th>\n",
       "      <th>azimuth min</th>\n",
       "      <th>azimuth max</th>\n",
       "      <th>azimuth step</th>\n",
       "      <th>dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>.\\data\\1</td>\n",
       "      <td>Strontium titanate</td>\n",
       "      <td>SrTiO3</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(170, 170)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      path            material composition  direction  thickness  \\\n",
       "1   1  .\\data\\1  Strontium titanate      SrTiO3  (0, 0, 1)        100   \n",
       "\n",
       "   thickness step  high tension  convergenc angle min  convergenc angle max  \\\n",
       "1               1            80                  15.0                  25.0   \n",
       "\n",
       "   convergenc angle step  mistilt min  mistilt max  mistilt step  azimuth min  \\\n",
       "1                    0.5            0           10             1            0   \n",
       "\n",
       "   azimuth max  azimuth step         dim  \n",
       "1          0.5           0.1  (170, 170)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN_trainer = CNN_PACBED_Trainer(parameters_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "joined-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be trained from (15.0 to 25.0) mrad convergence angle.\n",
      "Model will be trained from (0.0 to 99.8) nm thickness.\n",
      "Number of images: 138600\n",
      "90% used for training, 10% used for validation\n"
     ]
    }
   ],
   "source": [
    "CNN_trainer.filter_dataset(conv_range = parameters_training['conv_range'], thickness_range = parameters_training['thickness_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incident-colors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of CNN input: (170, 170, 3)\n"
     ]
    }
   ],
   "source": [
    "CNN_trainer.CNN_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sexual-window",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 100\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 170, 170, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Functional)           (None, 2048)         20861480    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     xception[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1025)         0           dropout_1[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          102600      concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 24,111,856\n",
      "Trainable params: 24,057,328\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/40\n",
      "15592/15592 [==============================] - 5398s 346ms/step - loss: 3.6496 - categorical_accuracy: 0.0670 - val_loss: 3.2380 - val_categorical_accuracy: 0.1330\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 2/40\n",
      "15592/15592 [==============================] - 2357s 151ms/step - loss: 2.1774 - categorical_accuracy: 0.2414 - val_loss: 2.0260 - val_categorical_accuracy: 0.3069\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 3/40\n",
      "15592/15592 [==============================] - 2282s 146ms/step - loss: 1.6315 - categorical_accuracy: 0.3675 - val_loss: 1.6554 - val_categorical_accuracy: 0.3864\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 4/40\n",
      "15592/15592 [==============================] - 2284s 146ms/step - loss: 1.3679 - categorical_accuracy: 0.4499 - val_loss: 1.8247 - val_categorical_accuracy: 0.3596\n",
      "Epoch 5/40\n",
      "15592/15592 [==============================] - 2291s 147ms/step - loss: 1.2013 - categorical_accuracy: 0.5110 - val_loss: 1.2855 - val_categorical_accuracy: 0.4914\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 6/40\n",
      "15592/15592 [==============================] - 2313s 148ms/step - loss: 1.0931 - categorical_accuracy: 0.5548 - val_loss: 0.9162 - val_categorical_accuracy: 0.6319\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 7/40\n",
      "15592/15592 [==============================] - 2306s 148ms/step - loss: 1.0123 - categorical_accuracy: 0.5949 - val_loss: 1.1895 - val_categorical_accuracy: 0.5396\n",
      "Epoch 8/40\n",
      "15592/15592 [==============================] - 2301s 148ms/step - loss: 0.9534 - categorical_accuracy: 0.6193 - val_loss: 1.2515 - val_categorical_accuracy: 0.5463\n",
      "Epoch 9/40\n",
      "15592/15592 [==============================] - 2307s 148ms/step - loss: 0.8879 - categorical_accuracy: 0.6496 - val_loss: 0.8435 - val_categorical_accuracy: 0.6650\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 10/40\n",
      "15592/15592 [==============================] - 2306s 148ms/step - loss: 0.8548 - categorical_accuracy: 0.6602 - val_loss: 1.1095 - val_categorical_accuracy: 0.5752\n",
      "Epoch 11/40\n",
      "15592/15592 [==============================] - 2303s 148ms/step - loss: 0.8169 - categorical_accuracy: 0.6799 - val_loss: 0.8516 - val_categorical_accuracy: 0.6619\n",
      "Epoch 12/40\n",
      "15592/15592 [==============================] - 2304s 148ms/step - loss: 0.7812 - categorical_accuracy: 0.6931 - val_loss: 0.7584 - val_categorical_accuracy: 0.6991\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 13/40\n",
      "15592/15592 [==============================] - 2305s 148ms/step - loss: 0.7529 - categorical_accuracy: 0.7061 - val_loss: 0.8372 - val_categorical_accuracy: 0.6666\n",
      "Epoch 14/40\n",
      "15592/15592 [==============================] - 2305s 148ms/step - loss: 0.7366 - categorical_accuracy: 0.7171 - val_loss: 0.6469 - val_categorical_accuracy: 0.7425\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 15/40\n",
      "15592/15592 [==============================] - 2311s 148ms/step - loss: 0.7133 - categorical_accuracy: 0.7274 - val_loss: 0.6640 - val_categorical_accuracy: 0.7350\n",
      "Epoch 16/40\n",
      "15592/15592 [==============================] - 2315s 148ms/step - loss: 0.6925 - categorical_accuracy: 0.7358 - val_loss: 0.5751 - val_categorical_accuracy: 0.7727\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 17/40\n",
      "15592/15592 [==============================] - 2311s 148ms/step - loss: 0.6724 - categorical_accuracy: 0.7463 - val_loss: 0.7641 - val_categorical_accuracy: 0.7071\n",
      "Epoch 18/40\n",
      "15592/15592 [==============================] - 2310s 148ms/step - loss: 0.6573 - categorical_accuracy: 0.7501 - val_loss: 1.1160 - val_categorical_accuracy: 0.6151\n",
      "Epoch 19/40\n",
      "15592/15592 [==============================] - 2306s 148ms/step - loss: 0.6422 - categorical_accuracy: 0.7569 - val_loss: 0.5427 - val_categorical_accuracy: 0.7897\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 20/40\n",
      "15592/15592 [==============================] - 2311s 148ms/step - loss: 0.6307 - categorical_accuracy: 0.7648 - val_loss: 0.5666 - val_categorical_accuracy: 0.7838\n",
      "Epoch 21/40\n",
      "15592/15592 [==============================] - 2315s 148ms/step - loss: 0.6259 - categorical_accuracy: 0.7684 - val_loss: 0.6307 - val_categorical_accuracy: 0.7520\n",
      "Epoch 22/40\n",
      "15592/15592 [==============================] - 2309s 148ms/step - loss: 0.6110 - categorical_accuracy: 0.7727 - val_loss: 0.9243 - val_categorical_accuracy: 0.6881\n",
      "Epoch 23/40\n",
      "15592/15592 [==============================] - 2313s 148ms/step - loss: 0.6045 - categorical_accuracy: 0.7767 - val_loss: 0.5184 - val_categorical_accuracy: 0.8039\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 24/40\n",
      "15592/15592 [==============================] - 2321s 149ms/step - loss: 0.5847 - categorical_accuracy: 0.7845 - val_loss: 0.6529 - val_categorical_accuracy: 0.7507\n",
      "Epoch 25/40\n",
      "15592/15592 [==============================] - 2324s 149ms/step - loss: 0.5782 - categorical_accuracy: 0.7885 - val_loss: 0.5618 - val_categorical_accuracy: 0.7850\n",
      "Epoch 26/40\n",
      "15592/15592 [==============================] - 2315s 148ms/step - loss: 0.5678 - categorical_accuracy: 0.7923 - val_loss: 0.6233 - val_categorical_accuracy: 0.7754\n",
      "Epoch 27/40\n",
      "15592/15592 [==============================] - 2319s 149ms/step - loss: 0.5658 - categorical_accuracy: 0.7948 - val_loss: 0.4682 - val_categorical_accuracy: 0.8266\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 28/40\n",
      "15592/15592 [==============================] - 2316s 149ms/step - loss: 0.5558 - categorical_accuracy: 0.7972 - val_loss: 0.5574 - val_categorical_accuracy: 0.7862\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15592/15592 [==============================] - 2319s 149ms/step - loss: 0.5481 - categorical_accuracy: 0.7995 - val_loss: 0.5903 - val_categorical_accuracy: 0.7779\n",
      "Epoch 30/40\n",
      "15592/15592 [==============================] - 2313s 148ms/step - loss: 0.5412 - categorical_accuracy: 0.8063 - val_loss: 0.4567 - val_categorical_accuracy: 0.8295\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 31/40\n",
      "15592/15592 [==============================] - 2316s 148ms/step - loss: 0.5279 - categorical_accuracy: 0.8098 - val_loss: 0.6953 - val_categorical_accuracy: 0.7403\n",
      "Epoch 32/40\n",
      "15592/15592 [==============================] - 2339s 150ms/step - loss: 0.5333 - categorical_accuracy: 0.8083 - val_loss: 0.7620 - val_categorical_accuracy: 0.7477\n",
      "Epoch 33/40\n",
      "15592/15592 [==============================] - 2553s 164ms/step - loss: 0.5134 - categorical_accuracy: 0.8161 - val_loss: 0.4459 - val_categorical_accuracy: 0.8345\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 34/40\n",
      "15592/15592 [==============================] - 2325s 149ms/step - loss: 0.5251 - categorical_accuracy: 0.8155 - val_loss: 0.6476 - val_categorical_accuracy: 0.7848\n",
      "Epoch 35/40\n",
      "15592/15592 [==============================] - 2319s 149ms/step - loss: 0.5098 - categorical_accuracy: 0.8190 - val_loss: 0.8229 - val_categorical_accuracy: 0.7276\n",
      "Epoch 36/40\n",
      "15592/15592 [==============================] - 2320s 149ms/step - loss: 0.5116 - categorical_accuracy: 0.8192 - val_loss: 0.7162 - val_categorical_accuracy: 0.7335\n",
      "Epoch 37/40\n",
      "15592/15592 [==============================] - 2308s 148ms/step - loss: 0.5003 - categorical_accuracy: 0.8251 - val_loss: 0.4837 - val_categorical_accuracy: 0.8233\n",
      "Epoch 38/40\n",
      "15592/15592 [==============================] - 2319s 149ms/step - loss: 0.4928 - categorical_accuracy: 0.8267 - val_loss: 0.5705 - val_categorical_accuracy: 0.7882\n",
      "Epoch 39/40\n",
      "15592/15592 [==============================] - 2317s 149ms/step - loss: 0.4962 - categorical_accuracy: 0.8276 - val_loss: 0.4385 - val_categorical_accuracy: 0.8347\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Thickness\\assets\n",
      "Epoch 40/40\n",
      "15592/15592 [==============================] - 2318s 149ms/step - loss: 0.4898 - categorical_accuracy: 0.8293 - val_loss: 0.4879 - val_categorical_accuracy: 0.8255\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "CNN_trainer.train_thickness(epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "twenty-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 11\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 170, 170, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Functional)           (None, 2048)         20861480    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     xception[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         1049600     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1025)         0           dropout_3[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 11)           11286       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 24,020,542\n",
      "Trainable params: 23,966,014\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "15592/15592 [==============================] - 2308s 148ms/step - loss: 1.6543 - categorical_accuracy: 0.3277 - val_loss: 2.6902 - val_categorical_accuracy: 0.1828\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 2/20\n",
      "15592/15592 [==============================] - 2311s 148ms/step - loss: 0.9547 - categorical_accuracy: 0.5990 - val_loss: 0.8567 - val_categorical_accuracy: 0.6283\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 3/20\n",
      "15592/15592 [==============================] - 2328s 149ms/step - loss: 0.7649 - categorical_accuracy: 0.6841 - val_loss: 0.8632 - val_categorical_accuracy: 0.6273\n",
      "Epoch 4/20\n",
      "15592/15592 [==============================] - 2505s 161ms/step - loss: 0.6536 - categorical_accuracy: 0.7310 - val_loss: 0.8193 - val_categorical_accuracy: 0.6596\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 5/20\n",
      "15592/15592 [==============================] - 2333s 150ms/step - loss: 0.5826 - categorical_accuracy: 0.7624 - val_loss: 0.5159 - val_categorical_accuracy: 0.7787\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 6/20\n",
      "15592/15592 [==============================] - 2343s 150ms/step - loss: 0.5139 - categorical_accuracy: 0.7920 - val_loss: 1.4797 - val_categorical_accuracy: 0.5206\n",
      "Epoch 7/20\n",
      "15592/15592 [==============================] - 2342s 150ms/step - loss: 0.4803 - categorical_accuracy: 0.8067 - val_loss: 0.5581 - val_categorical_accuracy: 0.7702\n",
      "Epoch 8/20\n",
      "15592/15592 [==============================] - 2338s 150ms/step - loss: 0.4308 - categorical_accuracy: 0.8270 - val_loss: 0.4234 - val_categorical_accuracy: 0.8180\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 9/20\n",
      "15592/15592 [==============================] - 2336s 150ms/step - loss: 0.3859 - categorical_accuracy: 0.8482 - val_loss: 1.1384 - val_categorical_accuracy: 0.6748\n",
      "Epoch 10/20\n",
      "15592/15592 [==============================] - 2338s 150ms/step - loss: 0.3644 - categorical_accuracy: 0.8608 - val_loss: 0.3848 - val_categorical_accuracy: 0.8464\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 11/20\n",
      "15592/15592 [==============================] - 2328s 149ms/step - loss: 0.3465 - categorical_accuracy: 0.8669 - val_loss: 0.3477 - val_categorical_accuracy: 0.8761\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 12/20\n",
      "15592/15592 [==============================] - 2329s 149ms/step - loss: 0.3327 - categorical_accuracy: 0.8726 - val_loss: 0.3044 - val_categorical_accuracy: 0.8772\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 13/20\n",
      "15592/15592 [==============================] - 2340s 150ms/step - loss: 0.3203 - categorical_accuracy: 0.8800 - val_loss: 1.3232 - val_categorical_accuracy: 0.5994\n",
      "Epoch 14/20\n",
      "15592/15592 [==============================] - 2341s 150ms/step - loss: 0.3271 - categorical_accuracy: 0.8801 - val_loss: 0.8365 - val_categorical_accuracy: 0.6970\n",
      "Epoch 15/20\n",
      "15592/15592 [==============================] - 2335s 150ms/step - loss: 0.2938 - categorical_accuracy: 0.8892 - val_loss: 0.2877 - val_categorical_accuracy: 0.8931\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Mistilt\\assets\n",
      "Epoch 16/20\n",
      "15592/15592 [==============================] - 2366s 152ms/step - loss: 0.3048 - categorical_accuracy: 0.8888 - val_loss: 0.3885 - val_categorical_accuracy: 0.8532\n",
      "Epoch 17/20\n",
      "15592/15592 [==============================] - 2372s 152ms/step - loss: 0.2767 - categorical_accuracy: 0.8980 - val_loss: 0.8894 - val_categorical_accuracy: 0.7252\n",
      "Epoch 18/20\n",
      "15592/15592 [==============================] - 2371s 152ms/step - loss: 0.2653 - categorical_accuracy: 0.9022 - val_loss: 2.7400 - val_categorical_accuracy: 0.4766\n",
      "Epoch 19/20\n",
      "15592/15592 [==============================] - 2369s 152ms/step - loss: 0.2560 - categorical_accuracy: 0.9058 - val_loss: 0.5741 - val_categorical_accuracy: 0.7987\n",
      "Epoch 20/20\n",
      "15592/15592 [==============================] - 2368s 152ms/step - loss: 0.2470 - categorical_accuracy: 0.9102 - val_loss: 0.4466 - val_categorical_accuracy: 0.8482\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "CNN_trainer.train_mistilt(epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ignored-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 7\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 170, 170, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Functional)           (None, 2048)         20861480    input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         2098176     xception[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         1049600     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1025)         0           dropout_5[0][0]                  \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 7)            7182        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 24,016,438\n",
      "Trainable params: 23,961,910\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "15592/15592 [==============================] - 2300s 147ms/step - loss: 0.3602 - categorical_accuracy: 0.8611 - val_loss: 0.1199 - val_categorical_accuracy: 0.9520\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Scale\\assets\n",
      "Epoch 2/10\n",
      "15592/15592 [==============================] - 2282s 146ms/step - loss: 0.0592 - categorical_accuracy: 0.9830 - val_loss: 0.0503 - val_categorical_accuracy: 0.9851\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Scale\\assets\n",
      "Epoch 3/10\n",
      "15592/15592 [==============================] - 2309s 148ms/step - loss: 0.0383 - categorical_accuracy: 0.9899 - val_loss: 0.4578 - val_categorical_accuracy: 0.8803\n",
      "Epoch 4/10\n",
      "15592/15592 [==============================] - 2312s 148ms/step - loss: 0.0394 - categorical_accuracy: 0.9911 - val_loss: 0.0075 - val_categorical_accuracy: 0.9978\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Scale\\assets\n",
      "Epoch 5/10\n",
      "15592/15592 [==============================] - 2310s 148ms/step - loss: 0.0324 - categorical_accuracy: 0.9921 - val_loss: 0.0479 - val_categorical_accuracy: 0.9802\n",
      "Epoch 6/10\n",
      "15592/15592 [==============================] - 2305s 148ms/step - loss: 0.0275 - categorical_accuracy: 0.9931 - val_loss: 0.2863 - val_categorical_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "15592/15592 [==============================] - 2339s 150ms/step - loss: 0.0263 - categorical_accuracy: 0.9940 - val_loss: 0.0033 - val_categorical_accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: .\\data\\1\\models\\0\\Scale\\assets\n",
      "Epoch 8/10\n",
      "15592/15592 [==============================] - 2332s 150ms/step - loss: 0.0295 - categorical_accuracy: 0.9937 - val_loss: 0.0045 - val_categorical_accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "15592/15592 [==============================] - 2540s 163ms/step - loss: 0.0250 - categorical_accuracy: 0.9938 - val_loss: 0.0116 - val_categorical_accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "15592/15592 [==============================] - 2315s 148ms/step - loss: 0.0245 - categorical_accuracy: 0.9950 - val_loss: 0.0091 - val_categorical_accuracy: 0.9961\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "CNN_trainer.train_scale(epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-lafayette",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
